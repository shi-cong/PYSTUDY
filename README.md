# 相关代码均测试（持续更新）
目前的形势还是这么的严峻，生存不易，逝者安息，生者奋发。主要对一些常用代码库进行了封装。
刚看了那些开源软件的代码，觉得自己的代码真的好丑，突然感觉，人生有一种相当的挫败和无力去实现梦想的感觉。

## 一、前程无忧爬虫
这个虫子，是我从2016年7月开始编写持续维护到今天的虫子，也1年多了。重写过两次，
现在是第三次被重写和修改，之前的需求很简单，
就是登陆，搜索，分页，投递简历。遇到的技术难点，一开始是登陆那个重定向
http到https，https又到http。之前投递是批量投递，这次是一个一个请求，
但是还是没有加入很多过滤，现在有考虑做职位统计，就是统计你投的这个职位
有多少胜算。我现在都有想考虑为自己弄一个ios app了，就是app上控制这个爬虫帮我投，
然后每天给我问好，主人已经帮你搞定了。你好好休息，哈哈。

### (1)、获取所有有关python的职位信息
![](https://github.com/shi-cong/review/blob/master/data/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-10-05%20%E4%B8%8B%E5%8D%885.29.09.png)

### (2)、统计爬虫并且工资在1万左右的人数最多的前100个
```sql
SELECT * FROM job51.my_apply where  job_name like '%爬虫%'  and pay like '%1.%' order by submit_nums desc limit 100;
```
![](https://github.com/shi-cong/review/blob/master/data/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-10-05%20%E4%B8%8A%E5%8D%886.15.58.png)
从图中可以看出的是，爬虫在深圳招聘的并不多，由此可以认为，我上次辞职是一次非常大的失误。
这里就只有一家深圳你我金融看起来还不错的公司，其它都不符合。

### (3)、统计爬虫并且在深圳的公司
```sql
SELECT * FROM job51.my_apply where  job_name like '%爬虫%'  and company_name like '%深圳%'  order by submit_nums desc limit 100;
```
![](https://github.com/shi-cong/review/blob/master/data/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-10-05%20%E4%B8%8A%E5%8D%886.29.46.png)
这个看起来更悲伤了，居然只有这么几个，总之在深圳现在招聘的都是高手中的高手，我这种
也算高手了啊，但是咱的学历低，一块砖头，人家都是一包水泥本科以上啊，但是我技术好啊，
技术好也要让别人看到，辞职有一个星期左右了吧，还家里蹲有点说不过去吧。


## 二、世纪佳缘爬虫
这个爬虫主要是我想收集交友网的妹子信息，然后再用程序模拟约会生成约会数据，
然后做k-NN近邻分类算法的测试数据的。不得不说他们后台还是很复杂的，首先，
账户可能有安全级别，解封条件大概是2天左右，验证码也防IP，解封条件1天左右。
目前我要的数据都已经拿到了，他们平台的验证码，还是比较容易破解的。

#### (1)、登陆抓包
是有IP限制的，假设你多次登陆，你就要输入验证码了，第一次是不用的，然后，会封IP的。
目前我已经拿到了我所要的数据。

### (2)、分页拿到的所有妹子（不包括手机号）
这个分页很容易，还是要解决登陆那边的问题，也就是IP的问题。

下面是抓到的一些样例数据
![](https://github.com/shi-cong/review/blob/master/data/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-10-05%20%E4%B8%8A%E5%8D%888.05.55.png)

符合我的女生一共有多少个呢？看看这个数据统计。
![](https://github.com/shi-cong/review/blob/master/data/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-10-05%20%E4%B8%8A%E5%8D%888.06.32.png)

## 三、智联招聘爬虫
有了前程无忧爬虫，这次当然要搞智联了。有了之前才能不断壮大自己的谋生之路。
#### (1)、登陆抓包
what is fuck，这个登陆我抓包分析了半小时，假如是第一次登陆，尝试次数不多，
那么登陆就不用验证码，反之，清掉cookie之后，后期就要验证码，但是官方的验证码第一次出现
都是数字相减的，我试了几次，第一次都是2，你点击图片刷新验证码的时候就不是了，所以，这里
存在验证码漏洞。lol，其中比较奇怪的是，他们的cookie值很诡异，似乎隐藏起来了，我用postman测试
之后，发现，如果不带cookie是会被nginx拦截的。

PS. 由于网页版的接口不好抓，我决定从app上找突破口，看能否从app找到数据接口。首先是启动ios模拟器，然后
在模拟器上安装智联招聘app，最后用wireshark抓包。或者用fiddler抓。

## 四、自制搜索引擎
原理简单：首先建一张表（关键字，标题，链接，简介，更新时间），这样就够了，这只是简单的，首先你要做全站搜索抓很多的页面，
然后存入表里，然后，用户点击搜索的时候就会弹出前10页。

问题是：首先得写个简单的html搜索页面，支持分页，打开搜索出来的页面时新建标签打开，然后，后台数据这按，我得写一个通用的爬虫，
第一个是，首先最好用的是抓百度和google的数据，但是这样有一个问题，那就是这样纯属于搬运数据，没有技术含量，还有一种，针对用户
做不同种类的信息收集，那这张表到底够吗？一张表的数据量起来后，这个表扛得住以后的搜索吗？这都是问题。

不管什么反正，表已经建好了。后面就是页面和搜集数据的爬虫了。

## 五、自制代理IP供应系统
之前为公司做了一个失败了，为什么呢，由于请求量太大，导致连代理IP都要把我封掉，VPS运营商也要把我封掉，目标网站也要封我，最后最绝望的是
连GFW也要封我，其实数据量小，还是小事，一旦数据量大起来，这个代理IP恐怕就不是那么容易的事情，毕竟资源是有限的，但是呢，用有限的资源去
做有限的事情是可取的，用有限的资源去做无限的事情，你们说这科学吗？假设想要资源无限，那首先，你在国家工信部必须有关系，政府鼓励你干这事情，
要不然，没关系，你的资源显然是有限。

so，我准备弄一点小规模的代理给自己用用，毕竟有时候还是想去抓点妹子图片，投投简历，抓抓包啥的。后面会更新到。这个是在我的搜索引擎完成后开始。